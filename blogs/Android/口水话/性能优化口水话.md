---
性能优化

---

[toc]

#### 启动优化

启动优化首先需要定义指标，也就是确定启动的起点和终点。起点一般选择 Application 的 attachBaseContext，终点一般选择 MainActivity 的 onWindowFocusChanged 时机。

这个过程会经历几个阶段，分别是 Application attachBaseContext、ContentProvider 注册、Application onCreate、Activity 的创建和页面渲染。

下面我就按照这几个阶段来说具体的优化措施。

首先是 Application 的 attachBaseContext 阶段，这个阶段一般来说不会有太多的业务代码，所以基本上也不会有耗时操作。不过在 4.x 机型上，会因为首次 MultiDex.install 导致严重耗时。优化思路就是，在第一次冷启动的时候，直接加载没有经过 opt 优化的原始 dex，然后在后台进程慢慢地做完 dex 的 opt 工作。

接着就是 ContentProvider 的优化，ContentProvider 会自动初始化并且调用其 attachInfo、onCreate 方法，我们可以减少 onCreate 方法里的耗时操作；如果 ContentProvider 非常多，也可以使用 JetPack 提供的 Startup 将多个初始化的 ContentProvider 聚合成一个来进行优化。

然后就是 Application 的 onCreate 阶段，这一阶段主要做的就是启动任务的初始化，包括业务组件的初始化、第三方库的初始化等。优化思路就是构建启动框架，启动任务多线/程初始化，启动任务按需加载，非启动必须的任务可以延后初始化。

最后就是 Activity 的创建和 UI 渲染阶段的优化。这一阶段可以把 SplashActivity 和 MainActivity 合并，手百的开屏是一个 View 添加到 MainActivity 上。剩下的就是 UI 渲染阶段的优化了，由于解析 xml 是一个 IO 过程、创建 View 实例是一个反射过程，所以我们可以优化 xml 层级、使用 ViewStub 的方式按需加载等，或者使用 x2c。

除此之外，还有一些其他的优化手段，比如说主线程消息队列调度，通过自定义 Printer，在 println 方法中遍历主线程消息队列，根据 msg.what 和 msg.target 把生命周期相关的消息提前执行。还有就是 GC 抑制，启动阶段避免 GC，启动后放开 GC。

#### 内存优化

内存优化主要是解决内存泄漏和内存抖动。 

内存泄露我主要的排查思路是使用 LeakCanary + Android Profiler。

LeakCanary 是一直开着的，但是时效性并不是很好，它需要累积到 5 次内存泄露才会 dump 出堆转储文件分析。所以一般在需求的收尾阶段，我会打开关闭页面四五次，通过 adb shell dumpsys meminfo {package name}，查看内存中的 Views 和 Activities 是不是一直在增长，如果是一直在增长的情况，基本上可以判定是存在内存泄露了。然后再使用 Android Profiler 强制 gc 多次之后，dump 出堆转储文件分析，现在 Android Profiler 已经可以自动分析泄漏的对象了，展示最接近 gc root 的引用链之后基本上都可以解决问题了，不像以前老版本的 Android Profiler 还需要自己手动搜索 Activity 实例来判断有没有发现泄露。

在项目中，遇到的内存泄露还是比较多的，有比较常见的 DialogFragment 未调用 onDestory 方法、有一些延迟任务的 Handler 未 removeCallbacksAndMessages，也有一些和业务强相关的比如播放器、落地页未及时销毁，还有和特定机型相关的内存泄露比如三星 7 的 EditText 的 TextChangedListener。

我们项目中也有 LeakCanary 检测出来的 Toast 的 mContext 泄漏，这个最开始一直复现不出来，我们也去官方的 Github 仓库搜对应的 issue 也发现有类型泄露，但是没人回复如何解决。经过我们不断的尝试，偶现了一次，但是是在弹出 Toast 时就立马堆转储文件分析了，如果 Toast 弹出后隔个十秒再堆转储就不会有这个问题，基本上可以确定是误报了。于是我们带着问题去看了 LeakCanary 的源码，发现有两点小小的问题可能会导致误报，第一点就是调用 Runtime.gc 可能并不会真正的开始 gc，gc 的时间点并不是确定的，第二点就是 sleep 100ms 让对象有足够的时间添加到其关联的引用队列里面，这一步在注释上写的也比较清楚，因为没有程序化的方法能够确定对象何时会被添加到其关联的引用队列里面。

LeakCanary 的实现原理比较简单，我也写过针对 Activity 的内存泄露检测，然后可以在 logcat 里面直接输出泄漏引用链。

内存抖动遇到的比较少，一般就是不要频繁的去创建对象销毁对象，典型的就是避免在 View 的 onDraw 方法中创建对象。还有就是避免在一个页面上不停的 decodeBitmap 切换图片导致大对象频繁的创建和销毁。

最后呢，还有一些通用的优化手段，比如 onTrimMemory 回调，这个方法会在 Vsync 信号到来时，Choreographer 执行 COMMIT 回调时执行，还有使用一些优化过的集合，比如 SparseArray、ArrayMap 等。这两个集合我也看过源码，SparseArray 用来替代 HashMap 的，但是 key 只能为 int 类型，简化了数据存储结构以及避免了自动装箱；ArrayMap 内部分别有两个长度为 10 的缓存队列用来缓存大小为 4 和 8 的 ArrayMap 对象，Bundle 内部就是使用 ArrayMap 存储数据的。

KOOM：

LeakCanary 是在 Activity onDestory 后强制 gc，通过检查其关联的引用队列有无该对象而判断是否发生了内存泄露，但是频繁的 gc 会导致用户明显的卡顿。KOOM 的做法是监控内存阈值，也就是周期性的查询 Java 堆内存、线程数、文件描述符数等资源占用情况，来判断是否触发 dump 堆转储文件。LeakCanary 还有一个问题是直接在主线程 dumpHprofData，这会严重阻塞主线程执行，KOOM 的做法是 fork 子进程去 dump 堆转储文件，然后再用 shark 库分析泄露引用链。

#### 包体积优化

包体积优化主要影响的是下载转化率。

Apk 包主要分为几个部分，libs so 库、dex、res、assets、resources.arsc 以及签名和 Manifest 文件。

常见的代码混淆、无用资源移除、ProGuard 等基本上大家都会做的，我主要做了资源精简这一块的优化，减少了 8M 左右。

首先是 png 图片，这是一个比较大的优化点，因为我们的最低 API 已经是 19 了，所以完全可以用 webp 替代 png。所以最开始我是写了一个 Task 来自动遍历 res 文件夹，使用 Google 开源的 cwebp 工具来转化，但是这有一个弊端，就是无法压缩第三方库里面的资源文件，所以在后面我们使用了 Gradle 3.3 版本新增的 getAllRawAndroidResources 这个 Api 可以获取到所有的资源目录，然后在进行转化。这一操作减少了 5.7M 的包体积大小。

还有就是遍历 res 生成 md5 值来去除重复的图片和 drawable，减少了133kb。最后配置了 resConfig，只保留中文和英文，减少了 1.1M，还可以在 devBuild 时配置 resConfig 只保留中文简体和 xxhdpi 的资源，有助于提升打包时间。

这些和权限输出，我都写在一个插件里面了。

除此之外呢，还有一些比较激进优化的手段，对于 libs so 库，可以选择只保留 arm64-v8a，基本上现在手机大多都是这个 CPU 架构；对于 dex 可以使用 Facebook 开源的 ReDex 进行 dex 重分包、去除行号信息；对于 resources.arsc 可以使用微信开源的 AndResGuard 对资源路径进行混淆；还有 R 文件内联等。

Android Gradle Plugin 其实是对 so 体积做了 strip 优化（stripReleaseDebugSymbols），也就是移除了调试信息和符号表。我们还可以开启 LTO（链接期优化），移除无用代码；合并 so 库，减少部分动态符号表项；提取多 so 库的共同依赖库。（美团）

dex 优化：

删除无用的代码指令，比如去除冗余的赋值、无副作用代码的删除等。

去除冗余的赋值，也就是删除一些类字段的赋值操作，这些字段如果赋值的是默认值的话，那么这些赋值字节码指令就可以直接删了，因为在类加载阶段，JVM 会进行赋值。

删除无副作用的代码，这个主要是指那些日志代码哈，它不仅会占用包体积大小，还会有一定的安全风险。删除日志代码，可以使用 proguard 的 assumenosideeffects（假设无效），配置以后 proguard 就会在 optimize 阶段删除 Log 相关的方法调用。但是它只会删除方法调用指令本身，并不会删除方法参数构造的字节码指令。这个就需要我们自己去实现了，也就是删除方法调用期间所有的字节码指令。

这俩手段都是通过去除无用的指令的思路来做的，那么我们还可以减少定义的方法或者字段数，从而减少 dex 数量。减少定义的方法数也就是指方法内联，具体做法就是 access 方法内联和 getter/setter 内联，也就是把具体的方法调用指令直接替换成字段访问指令。减少字段数，主要是指常量字段消除和 R 文件内联，也就是将常量值替换到使用处，从而减少字段的声明。

#### 布局优化

布局优化老生常谈了，说说我在项目中的一些实践手段吧。

首先考虑布局嵌套和过度绘制。

在写布局的时候，考虑是否有必要写布局，如果布局比较简单，是否可以选择直接 new，比如 RecyclerView 的 ItemView 可能就只是一个 TextView，这时 new TextView 显然比解析 xml 文件效率更高。如果要写布局文件了，考虑布局的复杂性，如果比较简单，FrameLayout 就行，如果布局比较复杂，可能导致嵌套过多，这时可以使用约束布局。同时为了后期维护性，我不建议使用线性布局。有时候，我们会封装一些控件放在系统控件里面，这时候就需要考虑是否可以 merge 最外层的布局。最后就是 ViewStub 延时初始化。处理布局嵌套就这些，可以通过 Layout Inspector 来查看布局层级。

接着是过度绘制，过度绘制可能是项目中遇到最多的了。首先记住最最重要的一点，就是在往顶层布局添加 background 时，一定要考虑是否有必要。我们的 Activity 的默认主题色是灰白色，如果 UI 图给的背景色是白色，基本上无一例外大家都会在顶层布局把 background 置为白色，这就导致了一层过度绘制，解决办法很简单，再写一个主题即可。还有些系统控件，默认是有背景色的，可以指定 background 为 null 即可，典型的就是 AppBarLayout 了。其次呢，就是代码层面的了，能少绘制就少绘制。比如 RecyclerView 的局部刷新、还有在选中/非选中的场景下，需要注意重复点击已选中的 Item 的处理以及在本地筛选数据的情况下，利用数据缓存避免重复处理数据。过度绘制就这些，可以使用开发者工具打开过度绘制查看。

除了上面比较常用的，还有一些优化手段可以考虑。比如使用 AsyncLayoutInflater 异步创建 View、使用掌阅开源的 X2C，这些都是建立在解析 Layout 是 IO 过程，创建 View 是通过反射为优化基础上的。

最后，布局优化还不能忽略后期的维护性，比如最好不要使用 LinearLayout，布局也可以写适当的注释，可以写适当的 tools 属性利于预览，当布局代码很多时，可以使用 editor-fold 来折叠代码块。

#### 卡顿优化

一般出现卡顿问题，都是流水线发现然后自动创建卡片丢给我们处理。导致卡顿的原因有很多，比如函数非常耗时、I/O 非常慢、线程间的竞争或者锁等，其实很多时候卡顿问题并不难解决，相较解决来说，更困难的是如何快速发现这些卡顿点，以及通过更多的辅助信息找到真正的卡顿原因。

这就引出了卡顿监控，卡顿监控有两种方式，分别是基于消息队列和字节码插桩。

基于消息队列的卡顿监控方案，主要思想是，监控主线程执行耗时，当超过阈值时，dump 出当前主线程的执行堆栈，通过堆栈分析找到卡顿原因。具体做法是，通过替换 Looper 的 Printer 实现，每一个消息的执行，都会在其前后打印日志，我们只需要设置这个 Printer，通过两次调用 println 的时间间隔，就是一个消息执行的耗时，这也是 [BlockCanary](https://github.com/markzhai/AndroidPerformanceMonitor/blob/master/blockcanary-analyzer/src/main/java/com/github/moduth/blockcanary/LooperMonitor.java#L50) 的核心实现。而 360 的 [ArgusAPM](https://github.com/Qihoo360/ArgusAPM/blob/master/argus-apm/argus-apm-main/src/main/java/com/argusapm/android/core/job/block/BlockTask.java#L60) 的做法相对优雅些，它是在消息分发的开始，去 postDelay 一个 Runnable，在消息分发的结束去移除这个 Runnable，如果在指定的 delay 时间内没有移除，就说明是发生卡顿了，这个 Runnable 所做的事情就是把当前线程的堆栈打印出来，这种做法其实就是 View 中判断长按事件的方式一样。

但是这两种方式都有相同的弊端，就是 println 参数有大量的字符串拼接，可能会导致性能损耗严重。

还有一种方案是，可以通过一个监控线程，每隔 1 秒向主线程消息队列的头部插入一条空消息。假设 1 秒后这个消息并没有被主线程消费掉，说明阻塞消息运行的时间在 0～1 秒之间。换句话说，如果我们需要监控 3 秒卡顿，那么在第四次轮询中头部消息依然没有被消费的话，就可以确定主线程出现了一次 3 秒以上的卡顿。

这两种方案，可以较方便的捕捉到卡顿的堆栈，但其最大的不足在于，无法获取到各个函数的执行耗时，对于稍微复杂一点的堆栈，很难找出可能耗时的函数，也就很难找到卡顿的原因。另外，通过其他线程循环获取主线程的堆栈，如果稍微处理不及时，很容易导致获取的堆栈有所偏移，不够准确，加上没有耗时信息，卡顿也就不好定位。还有就是，获取主线程堆栈的代价也是巨大的，它需要暂停主线程的运行。

**字节码插桩**

Matrix 的做法是，在编译期间收集所有生成的 class 文件，扫描文件内的方法指令进行统一的打点插桩。为了减少插桩量以及性能损耗，通过遍历 class 方法指令集，判断扫描的函数是否只含有 PUT/READ/FIELD 等简单的指令，来过滤一些默认或匿名构造函数，以及 get/set 等简单不耗时的函数。为了方便以及高效记录函数执行过程，会为每个插桩的函数分配一个独立的 ID，在插桩过程中，记录插桩的函数签名以及分配的 ID，在插桩完成后输出一份 mapping，作为数据上报后的解析支持。

通过向 Choreographer 注册监听，在每一帧 doFrame 回调时判断距离上一帧的时间差是否超过阈值，如果超过了阈值即判定发生了卡顿，这时候就会把两帧之间的所有函数执行信息进行上报分析。同时，在每一帧 doFrame 到来时，重置一个计时器，如果 5s 内没有 cancel，则认为是发生了 ANR。

**帧率 FPS**

FPS 可以衡量一个界面的流畅性，但往往不能很直观的衡量卡顿的发生。一个稳定在 40、50 FPS 的页面，我们不会认为是卡顿的，但一旦 FPS 很不稳定，人眼往往很容易感知到，因此我们可以通过掉帧程度来衡量卡顿。

业界都是使用 Choreographer 来监听应用的帧率，跟卡顿不同的是，需要排除掉页面没有操作的情况，我们应该只在界面存在绘制的时候做统计。那么如何监听界面是否存在绘制行为呢？可以通过 addOnDrawListener 实现：

```
getWindow().getDecorView().getViewTreeObserver().addOnDrawListener()
```

关于跳帧的判断，可以直接抄 Choreographer 的 doFrame 实现，源码内部判断跳帧次数 >=30 即意味着发生了卡顿。

**生命周期监控**

Activity、Service、Receiver 组件生命周期的耗时和调用次数也是我们重点关注的性能问题。例如 Activity 的 onCreate() 不应该超过 1 秒，不然会影响用户看到页面的时间。Service 和 Receiver 虽然是后台组件，不过它们的生命周期也是占用主线程的，也是我们需要关注的问题。

对于组件生命周期我们应该采用更严格的监控，可以全量上报各个组件各个生命周期的启动时间和启动次数。

一般的做法是，通过编译时插桩来做到组件的生命周期监控。

**线程监控**

线程间的竞争或者锁可能会导致主线程空等，从而导致卡顿。对于线程监控，需要监控以下两点：

1. 线程数量

   需要监控线程数量的多少，以及创建线程的方式。例如有没有使用统一的线程池，这块可以通过 hook 线程的 nativeCreate() 函数，主要用于进行线程收敛，减少线程数量。

2. 线程时间

   监控线程的用户时间 utime、系统时间 stime 和优先级。主要是看哪些线程 utime+stime 时间比较多，占用了过多的 CPU。

#### 崩溃优化

处理崩溃一般分为三步，分别是确定重点、查找共性、尝试复现。

首先是确定重点，看看崩溃的量级，以及是否是新上线的业务导致，来决定是否需要关闭实验或关闭流量入口，然后查找共性，是否是在特定的版本、机型或者系统上面发生，然后尝试复现。

崩溃一般分为三种，普通崩溃、系统崩溃和 ANR。

#### 普通崩溃

普通崩溃是指那些主要由于开发人员编写代码有误导致的崩溃，比如常见的：空指针、数组越界、类型转换异常、ConcurrentModificationException、NumberFormatException、JSONException 等等。解决这类 Crash 一般比较简单，更多的是考虑如何去避免。

NPE 可能是遇到过最频繁的，引起 NPE 一般有两种情况，一种是对象本身没有初始化就对其操作，还一种是对象已经初始化了，但是被回收或者手动置为 null了，然后又对其进行操作。针对第一种情况的原因有很多，可能是开发人员的失误、API 返回数据异常等等，针对这种情况，我们可以做的是，对可能为空的对象进行判空、养成使用 @NouNull @Nullable 注解的习惯、使用 Kotlin 语言。

针对第二种情况大部分是由于 Activity/Fragment 销毁或者被移除后，在 Listener、Runnable 等回调中执行一些代码导致，我们可以做的是，在回调时判断 Activity/Fragment 是否销毁或移除，或者在 Activity/Fragment 销毁时移除回调。

但是单纯的靠约定或规范去减少 Crash 的发生是不现实的，这时候可以集众人智慧或者自动化工具帮我们去避免这种问题。比如在发起 PR 时，流水线会自动跑 commit 的 diff 点去发现潜在的问题，以及 PR 必须组内两位同学的 +2 后才能和入等等。

#### 系统崩溃

系统崩溃是指由于 Android 系统 bug 或者厂商 ROM 定制导致的崩溃，这类崩溃一般也不好解决，只能去尽量规避。

比如典型的有 7.1 Toast BadTokenException、Finalizer 导致的 TimeoutException、提供远程服务的进程挂掉导致的 DeadObjectException 等等。

解决这类问题，一般的处理方式有三种。一种是去翻源码 try-catch，比如解决 BadTokenException，Android 8 就是直接 try-catch 解决。第二种是设置 UncaughtExceptionHandler，滴滴解决 TimeoutException 的做法是，如果 Thread 是 FinalizerWatchdogDaemon 线程并且异常类型是 TimeoutException 直接忽略即可。第三种方式是，反射设置 ActivityThread.mH.mCallback，然后在这个 Handler.Callbcak 中判断是堆栈是系统的类，则直接 try-catch。这样就完成了对系统崩溃的兜底，而不会掩盖掉业务异常，这正是 Booster 为系统崩溃兜底的方案。

#### ANR

当发生 ANR 的时候，首先判断下是否受系统因素影响，这里所说的系统因素通常指的是整机负载/低内存/系统异常等。CPU 负载超 85% 说明负载过高，当内存吃紧时，kswapd 线程会活跃起来进行回收内存，GC 也会更加频繁，甚至可能会触发 lowmemorykiller 机制杀进程，可用内存占比 trace 文件中也有，如果存在上述情况，说明这次的 ANR 的进程可能只是受害者。然后再看看主线程的堆栈，是否是因为锁等待导致，或者主线程存在耗时操作。

**ANR 的信息收集过程**

当发生 ANR 的时候，会开启一个 AnrConsumer 的线程去处理 ANR，这个线程主要做的事情就是收集一些现场信息，比如当前进程名、进程的 pid、以及发生 ANR 的原因，剩下的就是 ProcessCpuTracker 输出的一些关键信息，包括 CPU 负载、内存使用率以及进程列表中各个线程的用户时间和系统时间占比等等。然后输出 logcat、写入 traces 文件，最后根据是否是前台进程来决定是否弹一个 ANR 弹窗。这里需要注意的是，写入 trace 文件是包含许多进程的 trace 信息的，因为产生 ANR 的原因有可能是其他进程抢占了太多资源，或者 IPC 到其他进程（尤其是系统进程）的时候卡住导致的。

**ANR 监控**

监控 ANR 通常有三种做法：

- 使用 FileObserver 监听 /data/anr/traces.txt 的变化

  不过高版本系统已经没有读取这个文件的权限了，同时高版本系统也不再是只能生成一个 traces 文件了，而是可以生成多个带时间戳的 traces 文件，可以使用 adb bugreport 导出 traces 文件本地分析。

- 监控消息队列的运行时间

  这个在卡顿优化里面提到过，完全可以看成是对卡顿 5 秒的监控，所以基于 Looper Printer 的方案也是可以用的。除此之外，[ANR-WatchDog](https://github.com/SalomonBrys/ANR-WatchDog) 也是类似原理。它是通过在一个工作线程中，用主线程的 Handler post 一个消息，然后这个线程直接 sleep 5s，sleep 之后看看标志位是否被修改，如果没被修改就说明主线程卡顿了 5s，即发生了 ANR。

- 监听 SIGQUIT 信号

  这个来源于微信的 ANR 监控方案，这个原理是，当发生 ANR 的时候，系统会向发生 ANR 的进程发送一个 SIGQUIT 信号来 dump 进程堆栈。发生 ANR 的进程一定会收到 SIGQUIT 信号，但收到 SIGQUIT 信号的进程并不一定发生了 ANR。原因是发生了 ANR 时，系统并不只是会 dump 发生了 ANR 的进程，还会 dump 一些其他进程、比如 system_server 进程等，所以存在误报的情况。解决办法就是在监听 SIGQUIT 信号后，在 20s （20s 是 ANR dump 的 timeout 时间）内不断的轮询自己是否被设置了 NOT_RESPONDING 标志位，一旦发现有这个 flag，那么就可以认定是发生了一次 ANR。

**常见案例**

1. SharedPrederence apply 引起的 ANR 问题

   这个问题的根因是，SP 调用 apply 方法，会创建一个等待锁放到 QueuedWork 中，并将真正数据持久化封装成一个任务放到异步队列中执行，任务执行结束后释放锁。Activity onPause 时执行 QueuedWork.waitToFinish() 等待所有的等待锁释放，等待超时则发生 ANR。其实不管是 commit 还是 apply，都是在主线程进行 IO 操作，那么都是可能会产生 ANR 的。

   那么这个问题如何去解决呢？字节的做法是清空等待锁队列，而 Booster 最初的做法是将 apply() 替换成 commit() 并在子线程中执行，这个方案的的优点是改动很小，风险相对较小，缺点是在调用 commit() 后立即调用 getXxx() 可能会导致 bug，毕竟异步调用 commit() 确实会有一定的概率出现数据不同步。

2. WebView 初始化，会锁住主线程导致 ANR

   从主线程堆栈来看，main 线程处于 waiting 状态，根本原因在于 *WebView* 在实例化的时候，需要先初始化 *Chromium* 引擎，而 *Chromium* 引擎又是一个重量级的组件，而且很多初始化的工作都需要在主线程中完成，这样就很容易造成主线程卡顿甚至 *ANR*。

   解决办法呢就是，预加载 Chromium 引擎，在主线程 IDLE 时去反射调用初始化 Chromium。

3. 生成路由表的时候 load 大量 class 文件导致 ANR

4. 低端机发生异常时，dump 异常堆栈过于耗时导致 ANR

   异常实例的构造是十分昂贵的，这是由于在构造异常实例时，Java 虚拟机便需要生成该异常的栈轨迹。该操作会逐一访问当前线程的 Java 栈帧，并且记录下各种调试信息，包括栈帧所指向方法的名字、方法所在的类名、文件名，以及在代码中的第几行触发该异常。

#### OOM

导致 OOM 的原因大部分如下：

1. 内存泄露，大量无用对象没有被及时回收导致后续申请内存失败
2. 大内存对象过多，最常见的大对象就是 Bitmap，几个大图同时加载很容易触发 OOM

**内存泄露**

内存泄露指系统未能及时释放已经不再使用的内存对象，一般是由错误的程序代码逻辑引起的。在 Android 平台上，最常见也是最严重的内存泄露就是 Activity 对象泄露。Activity 承载了 App 的整个界面功能，Activity 的泄漏同时也意味着它持有的大量资源对象都无法回收，极其容易造成 OOM。

**Bitmap**

我们可以通过 Bitmap.getAllocationByteCount() 方法获取 Bitmap  占用的字节大小。

Bitmap 加载优化分为几点：

1. 修改图片加载的 Config，即 BitmapFactory.Options 的 inPreferredConfig，比如可以指定为 Bitmap.Config.RGB_565，也就是一个像素占用 2 个字节。

2. Bitmap 复用

   比如在一个页面切换图片时，可以做 Bitmap 复用，也就是 Options.inBitmap 参数。

3. 图片分区显示

   当展示图片很大很长时，可以使用 BitmapRegionDecoder 分区加载。

4. Bitmap 缓存

   在一些列表上来回滑动，Bitmap 可能会在短时间内加载并销毁，这种情况下可以使用适当的缓存，比如使用 LruCache。

#### 编译优化

Gradle 的构建分为三个阶段，分别是 Initialzation、Configuration 和 Execution 阶段。可以在项目中，使用 build --scan 来进行性能分析，查看这三个阶段做了哪些事情以及耗费了多少时间。下面我就从这三个阶段来着手优化。

在 Initialzation 阶段，可以在 gradle.properties 中开启构建缓存和并行构建，也可以适当增加内存分配；

在 Configuration 阶段，避免使用动态版本和快照版本，动态版本即 1.0.+ 这种方式，快照版本即 SNAPSHOT，这两种方式都会迫使 Gradle 链接到远程仓库检查是否有依赖更新，默认有效期是 24h。我在项目中就发现一个友盟的 analyze 库使用了动态版本，然后就改为固定版本号；这个可以通过 scan 后的报告里面的 Dependencies 搜索 Dynamic version 查找所有的动态版本。然后就是调整 repo 顺序并过滤请求，也就是把内部的 maven 仓库放在最前面，因为 Gradle 在查找远程库时，是串行查询所有 repo 中的 maven 地址的，直到找到可用的依赖，所以应该把最快和最高命中率的仓库放在前面。同时，在 Gradle 5.1 开始，可以指定特定 repo 下载特定的包名的依赖，然后我就在我们内部的 maven 库过滤 com.ehi 的依赖，这一操作能有效的减少 Configuration 阶段的时间；还有一个比较常见的会导致 Configuration 阶段性能劣化的实现便是对 Gradle 中的集合类调用 all 或 each，比如 tasks.each 遍历 task，这会导致 taskGraph 的所有的 task 均被创建，可以把它替换成 configureEach 来避免。同样的对于创建 task，我们尽量也是使用 tasks.register 注册 task，而不是 tasks.create，create 操作会导致该 Task 在 Configure 阶段被立即创建并执行。

我们知道构建缓存可以显著提升构建速度，在配置阶段的生成的中间结果是否也可以缓存呢？答案的肯定的。也就是配置缓存，不过这个特性目前还在试验阶段，开启配置缓存后，Gradle 会缓存要运行的任务集的信息、配置以及其依赖项信息。这些缓存的条目都放在了 ./gradle/configuration-cache/ 目录下，以我们 help task 运行为例，开启了配置缓存，第二次运行时间减少了一半。

在 Execution 阶段，可以通过 -x 跳过不需要的 Task。我是在自己的 AS 里面配置 -x test -x lint 过滤掉 Test 和 Lint 相关的 Task，这俩任务在 Debug 阶段基本上不需要，但是会占用不少时间，特别是 lint，会默认生成 lint 报告。除此之外，我们还可以关闭 AAPT2 自带的 png 压缩和 png 的合法性检查、关闭多 abi 和多 density 的构建以及通过 resConfigs 来最小化使用资源文件。resConfigs 不仅可以减少包体积，在 debug 时可以选择只构建中文简体和 xxhdpi 的资源。

当然，在 Execution 阶段，比较耗时的任务当属编译 class 文件了。那么我们可以把依赖都打成 AAR 包引入，在开发时只需要打开特定的几个仓库源码即可。

构建性能分析，需要衡量不同的插件版本、Gradle 版本以及 JVM 设置对性能的影响，这一块可以使用 Gradle 提供的 gradle-profiler 工具来分析，它提供了基准化分析模式，可以针对不同的 Gradle 版本、不同的 CPU 内存设置、增量构建等进行性能分析。
